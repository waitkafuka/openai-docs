import{_ as s,c as n,o as a,V as l}from"./chunks/framework.61392f5d.js";const u=JSON.parse('{"title":"聊天功能","description":"","frontmatter":{},"headers":[],"relativePath":"guides/chat.md","filePath":"guides/chat.md","lastUpdated":null}'),o={name:"guides/chat.md"},p=l(`<h1 id="聊天功能" tabindex="-1">聊天功能 <a class="header-anchor" href="#聊天功能" aria-label="Permalink to &quot;聊天功能&quot;">​</a></h1><p>利用聊天补全 API，您可以使用 <code>gpt-3.5-turbo</code> 和 <code>gpt-4</code> 构建自己的应用程序，它可以做以下事情：</p><ul><li>起草电子邮件或其他写作</li><li>编写 Python 代码</li><li>回答有关一组文件的问题</li><li>创建对话客户端</li><li>为您的软件提供自然语言接口</li><li>辅导各种学科</li><li>翻译语言</li><li>为视频游戏模拟角色等等 本指南介绍如何<a href="https://platform.openai.com/docs/api-reference/chat" target="_blank" rel="noreferrer">使用 API 调用基于聊天的语言模型</a>，并分享获取良好结果的技巧。您还可以在 <a href="https://platform.openai.com/playground?mode=chat" target="_blank" rel="noreferrer">OpenAI Playground</a> 中尝试使用新的聊天格式。</li></ul><h2 id="介绍" tabindex="-1">介绍 <a class="header-anchor" href="#介绍" aria-label="Permalink to &quot;介绍&quot;">​</a></h2><p>聊天模型将一系列消息作为输入，并将模型生成的消息作为输出返回。</p><p>尽管聊天格式旨在使多轮对话易于进行，但它对没有任何对话的单轮任务同样有用（例如以前由指令跟随模型如 <code>text-davinci-003</code> 提供的服务）。</p><p>示例 API 调用如下所示：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#676E95;font-style:italic;"># Note: you need to be using OpenAI Python v0.27.0 for the code below to work</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> openai</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">openai</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">ChatCompletion</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">create</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">  </span><span style="color:#A6ACCD;font-style:italic;">model</span><span style="color:#89DDFF;">=</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gpt-3.5-turbo</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">  </span><span style="color:#A6ACCD;font-style:italic;">messages</span><span style="color:#89DDFF;">=[</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">system</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">You are a helpful assistant.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">user</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Who won the world series in 2020?</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">assistant</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">The Los Angeles Dodgers won the World Series in 2020.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#82AAFF;">        </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">user</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#82AAFF;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Where was it played?</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>主要的输入是消息参数。消息必须是消息对象的数组，其中每个对象具有角色（“系统”，“用户”或“助手”）和内容（消息的内容）。对话可以短到 1 个消息或填满许多页面。</p><p>通常，对话以系统消息开头，然后是交替的用户和助手消息。</p><p>系统消息有助于设置助手的行为。在上面的示例中，助手被指示为“您是一个有用的助手”。</p><div class="tip custom-block"><p class="custom-block-title">提示</p><p>gpt-3.5-turbo-0301 并不总是强烈关注系统消息，未来的模型将被训练以更强烈地关注系统消息。</p></div><p>用户消息有助于指导助手。它们可以由应用程序的最终用户生成，也可以作为指令由开发人员设定。</p><p>助手消息有助于存储先前的响应。它们也可以由开发人员编写，以帮助提供所需行为的示例。</p><p>包含对话历史记录有助于当用户指令涉及先前的消息时，系统进行回复。在上面的示例中，用户的最后一个问题“它在哪里进行？”只有在关于 2020 年世界系列赛的先前消息上下文中才有意义。因为模型没有记忆先前的请求，所有相关信息必须通过对话提供。如果对话无法适应模型的令牌限制，它必须以某种方式缩短。</p><h2 id="响应格式" tabindex="-1">响应格式 <a class="header-anchor" href="#响应格式" aria-label="Permalink to &quot;响应格式&quot;">​</a></h2><p>示例 API 响应如下所示：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">id</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">chatcmpl-6p9XYPYSTTRi0xEviKjjilqrWU2Ve</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">object</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">chat.completion</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">created</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">1677649420</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">model</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">gpt-3.5-turbo</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">usage</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">prompt_tokens</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">56</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">completion_tokens</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">31</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">total_tokens</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">87</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">choices</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#A6ACCD;">   </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">message</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">{</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">assistant</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">The 2020 World Series was played in Arlington, Texas at the Globe Life Field, which was the new home stadium for the Texas Rangers.</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">finish_reason</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">stop</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#A6ACCD;">    </span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">index</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">0</span></span>
<span class="line"><span style="color:#A6ACCD;">   </span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;">]</span></span>
<span class="line"><span style="color:#89DDFF;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>在 Python 中，助手的回应可以使用 <code>response[&#39;choices&#39;][0][&#39;message&#39;][&#39;content&#39;]</code>获取。</p><p>每个响应都将包括一个 finish_reason。finish_reason 的可能值为：</p><ul><li><code>stop</code>：API 返回完整的模型输出</li><li><code>length</code>：由于 <a href="https://platform.openai.com/docs/api-reference/chat/create#chat/create-max_tokens" target="_blank" rel="noreferrer">max_tokens 参数</a>或令牌限制导致不完整的模型输出</li><li><code>content_filter</code>：由于内容过滤器的标志而省略的内容</li><li><code>null</code>：API 响应仍在进行或不完整</li></ul><h2 id="管理令牌-token" tabindex="-1">管理令牌（token） <a class="header-anchor" href="#管理令牌-token" aria-label="Permalink to &quot;管理令牌（token）&quot;">​</a></h2><p>语言模型以被称为令牌的块读取文本。在英语中，令牌可以短至一个字符或长至一个单词（例如，a 或 apple），在某些语言中，令牌甚至可以比一个字符更短或比一个单词更长。</p><p>例如，<code>“ChatGPT is great！”</code>字符串被编码为六个令牌：<code>[“Chat”，“G”，“PT”，“ is”，“ great”，“！”]</code>。</p><p>API 调用中令牌的总数影响以下几个方面：</p><ul><li>您的 API 调用成本，因为按令牌计费</li><li>您的 API 调用需要的时间，因为编码更多令牌需要更多时间</li><li>您的 API 调用是否起作用，因为总令牌必须低于模型的最大限制（<code>gpt-3.5-turbo-0301</code> 的 4096 个令牌）</li></ul><p>输入和输出令牌都计入这些数量。例如，如果您的 API 调用在消息输入中使用了 10 个令牌，并且您在消息输出中收到了 20 个令牌，则将为您计费 30 个令牌。</p><p>要查看 API 调用使用了多少令牌，请检查 API 响应中的 <code>usage</code> 字段（例如，<code>response[&#39;usage&#39;][&#39;total_tokens&#39;]</code>）。</p><p>像 <code>gpt-3.5-turbo</code> 和 <code>gpt-4</code> 这样的聊天模型以与其他模型相同的方式使用令牌，但由于其基于消息的格式，对令牌数量的计算更加困难。</p><details class="details custom-block"><summary>深入挖掘 token 计算</summary><p>以下是一个用于计算传递到 <code>gpt-3.5-turbo-0301</code> 的消息标记的函数示例。 消息转换为令牌的确切方式可能因模型而异。因此，当未来的模型版本发布时，此功能返回的答案可能只是近似值。 <a href="https://github.com/openai/openai-python/blob/main/chatml.md" target="_blank" rel="noreferrer">ChatML 文档</a>解释了 OpenAI API 如何将消息转换为 token，并且可能有助于编写您自己的函数。</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#C792EA;">def</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">num_tokens_from_messages</span><span style="color:#89DDFF;">(</span><span style="color:#A6ACCD;font-style:italic;">messages</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#A6ACCD;font-style:italic;">model</span><span style="color:#89DDFF;">=</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gpt-3.5-turbo-0301</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">):</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span><span style="color:#676E95;font-style:italic;">Returns the number of tokens used by a list of messages.</span><span style="color:#89DDFF;font-style:italic;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;font-style:italic;">try</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      encoding </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> tiktoken</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">encoding_for_model</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;font-style:italic;">except</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">KeyError</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      encoding </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> tiktoken</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">get_encoding</span><span style="color:#89DDFF;">(</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">cl100k_base</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> model </span><span style="color:#89DDFF;">==</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gpt-3.5-turbo-0301</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;font-style:italic;"># note: future models may deviate from this</span></span>
<span class="line"><span style="color:#A6ACCD;">      num_tokens </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">0</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> message </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> messages</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">          num_tokens </span><span style="color:#89DDFF;">+=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">4</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;font-style:italic;"># every message follows &lt;im_start&gt;{role/name}\\n{content}&lt;im_end&gt;\\n</span></span>
<span class="line"><span style="color:#A6ACCD;">          </span><span style="color:#89DDFF;font-style:italic;">for</span><span style="color:#A6ACCD;"> key</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> value </span><span style="color:#89DDFF;font-style:italic;">in</span><span style="color:#A6ACCD;"> message</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">items</span><span style="color:#89DDFF;">():</span></span>
<span class="line"><span style="color:#A6ACCD;">              num_tokens </span><span style="color:#89DDFF;">+=</span><span style="color:#A6ACCD;"> </span><span style="color:#82AAFF;">len</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">encoding</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">encode</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">value</span><span style="color:#89DDFF;">))</span></span>
<span class="line"><span style="color:#A6ACCD;">              </span><span style="color:#89DDFF;font-style:italic;">if</span><span style="color:#A6ACCD;"> key </span><span style="color:#89DDFF;">==</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">name</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;font-style:italic;"># if there&#39;s a name, the role is omitted</span></span>
<span class="line"><span style="color:#A6ACCD;">                  num_tokens </span><span style="color:#89DDFF;">+=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">-</span><span style="color:#F78C6C;">1</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;font-style:italic;"># role is always required and always 1 token</span></span>
<span class="line"><span style="color:#A6ACCD;">      num_tokens </span><span style="color:#89DDFF;">+=</span><span style="color:#A6ACCD;"> </span><span style="color:#F78C6C;">2</span><span style="color:#A6ACCD;">  </span><span style="color:#676E95;font-style:italic;"># every reply is primed with &lt;im_start&gt;assistant</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#89DDFF;font-style:italic;">return</span><span style="color:#A6ACCD;"> num_tokens</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;font-style:italic;">else</span><span style="color:#89DDFF;">:</span></span>
<span class="line"><span style="color:#A6ACCD;">      </span><span style="color:#89DDFF;font-style:italic;">raise</span><span style="color:#A6ACCD;"> </span><span style="color:#FFCB6B;">NotImplementedError</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;&quot;&quot;num_tokens_from_messages() is not presently implemented for model </span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">model</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;">.</span></span>
<span class="line"><span style="color:#C3E88D;">  See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.&quot;&quot;&quot;</span><span style="color:#89DDFF;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p>接下来，创建一条消息并将其传递给上面定义的函数，以查看令牌计数，这应该与 API 返回的值匹配。</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">messages </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">system</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">You are a helpful, pattern-following assistant that translates corporate jargon into plain English.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">system</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">name</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">example_user</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">New synergies will help drive top-line growth.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">system</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">name</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">example_assistant</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Things working well together will increase revenue.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">system</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">name</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">example_user</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Let&#39;s circle back when we have more bandwidth to touch base on opportunities for increased leverage.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">system</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">name</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">example_assistant</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">Let&#39;s talk later when we&#39;re less busy about how to do better.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#A6ACCD;">  </span><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">user</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">,</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">content</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">:</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">This late pivot means we don&#39;t have time to boil the ocean for the client deliverable.</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">},</span></span>
<span class="line"><span style="color:#89DDFF;">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">model </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> </span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">gpt-3.5-turbo-0301</span><span style="color:#89DDFF;">&quot;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&quot;</span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">num_tokens_from_messages</span><span style="color:#89DDFF;">(</span><span style="color:#82AAFF;">messages</span><span style="color:#89DDFF;">,</span><span style="color:#82AAFF;"> model</span><span style="color:#89DDFF;">)</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> prompt tokens counted.&quot;</span><span style="color:#89DDFF;">)</span></span>
<span class="line"><span style="color:#676E95;font-style:italic;"># Should show ~126 total_tokens</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p>为了确认上述函数生成的数字与 API 返回的数字相同，请创建一个新的聊天接口调用：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#676E95;font-style:italic;"># example token count from the OpenAI API</span></span>
<span class="line"><span style="color:#89DDFF;font-style:italic;">import</span><span style="color:#A6ACCD;"> openai</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#A6ACCD;">response </span><span style="color:#89DDFF;">=</span><span style="color:#A6ACCD;"> openai</span><span style="color:#89DDFF;">.</span><span style="color:#F07178;">ChatCompletion</span><span style="color:#89DDFF;">.</span><span style="color:#82AAFF;">create</span><span style="color:#89DDFF;">(</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">model</span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;">model</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">messages</span><span style="color:#89DDFF;">=</span><span style="color:#82AAFF;">messages</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#82AAFF;">    </span><span style="color:#A6ACCD;font-style:italic;">temperature</span><span style="color:#89DDFF;">=</span><span style="color:#F78C6C;">0</span><span style="color:#89DDFF;">,</span></span>
<span class="line"><span style="color:#89DDFF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#82AAFF;">print</span><span style="color:#89DDFF;">(</span><span style="color:#C792EA;">f</span><span style="color:#C3E88D;">&#39;</span><span style="color:#F78C6C;">{</span><span style="color:#82AAFF;">response</span><span style="color:#89DDFF;">[</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">usage</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">][</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">prompt_tokens</span><span style="color:#89DDFF;">&quot;</span><span style="color:#89DDFF;">]</span><span style="color:#F78C6C;">}</span><span style="color:#C3E88D;"> prompt tokens used.&#39;</span><span style="color:#89DDFF;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div></details><p>要在不进行 API 调用的情况下查看文本字符串中有多少个令牌，请使用 OpenAI 的 <a href="https://github.com/openai/tiktoken" target="_blank" rel="noreferrer">tiktoken</a> Python 库。示例代码可以在 OpenAI Cookbook 的 <a href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb" target="_blank" rel="noreferrer">tiktoken 计数令牌的指南</a>中找到。</p><p>传递给 API 的每条消息都会消耗 token，包括内容、角色和其他字段，以及一些额外的隐藏格式。这些未来可能会有变化。</p><p>如果对话具有太多的令牌，超出了模型的最大限制（例如，<code>gpt-3.5-turbo</code> 的 4096 个以上的令牌），则必须将您的文本截断，省略或缩小，直到其符合大小。请注意，如果从消息输入中删除了消息，则模型将失去所有有关它的知识。</p><p>还要注意，非常长的对话更有可能收到不完整的回复。例如，一个长度为 4090 个令牌的 <code>gpt-3.5-turbo</code> 对话在仅 6 个令牌后就被截断了。</p><h2 id="调教模型" tabindex="-1">调教模型 <a class="header-anchor" href="#调教模型" aria-label="Permalink to &quot;调教模型&quot;">​</a></h2><p>调教模型的最佳实践可能会随着模型版本升级而改变。以下的建议适用于 <code>gpt-3.5-turbo-0301</code>，可能不适用于未来的模型。</p><p>许多对话以一个系统消息绅士地指导助手开始。例如，这是 ChatGPT 使用的其中一条系统消息:</p><div class="tip custom-block"><p class="custom-block-title">prompt</p><p>You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible. Knowledge cutoff: {knowledge_cutoff} Current date:</p></div><p>一般来说，<code>gpt-3.5-turbo-0301</code> 不会过分关注系统消息，因此重要的指令通常最好放在用户消息中。</p><p>如果模型没有生成您想要的输出，请随时迭代并尝试改进。您可以尝试如下方法：</p><ul><li>使您的指导更加明确</li><li>指定您希望答案的格式</li><li>要求模型在做出答案之前逐步思考或辩论利弊</li></ul><p>有关更多提示工程化的想法，请阅读 <a href="https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md" target="_blank" rel="noreferrer">OpenAI cookbook 指南</a>，了解如何提高可靠性的技术。</p><p>除了系统消息之外，<code>temperature</code> 和 <code>max_tokens</code> 是开发人员有很多选项来<a href="https://platform.openai.com/docs/api-reference/chat" target="_blank" rel="noreferrer">影响聊天模型输出中的两个选项</a>。对于 <code>temperature</code>，像 0.8 这样更高的值会使输出更加随机，而像 0.2 这样更低的值会使其更加专注和确定性。在 <code>max_tokens</code> 的情况下，如果您想将响应限制在一定长度范围内，最大标记可以设置为任意数字。例如，如果您将最大标记值设置为 5，则输出将被截断，结果对用户来说是不合理的。</p><h2 id="chat-vs-completion" tabindex="-1">Chat VS Completion <a class="header-anchor" href="#chat-vs-completion" aria-label="Permalink to &quot;Chat VS Completion&quot;">​</a></h2><p>由于 <code>gpt-3.5-turbo</code> 的性能与 <code>text-davinci-003</code> 相似，但每个标记的价格只有其 10％，因此我们建议在大多数用例中使用 <code>gpt-3.5-turbo</code>。</p><p>对于许多开发人员，转换就像简单地重新编写和重新测试 prompt 一样简单。</p><p>例如，如果您使用以下完成提示将英语翻译为法语：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">将以下英语文本翻译为法语：“{text}”</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>那么以 Chat API 来调用就像下面这样：</p><div class="language-python line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#89DDFF;">[</span></span>
<span class="line"><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;">：“system”，“content”：“您是一个有用的助手，可以将英语翻译成法语。”</span><span style="color:#89DDFF;">}</span><span style="color:#A6ACCD;">，</span></span>
<span class="line"><span style="color:#89DDFF;">{</span><span style="color:#89DDFF;">&quot;</span><span style="color:#C3E88D;">role</span><span style="color:#89DDFF;">&quot;</span><span style="color:#A6ACCD;">：“user”，“content”：</span><span style="color:#89DDFF;">&#39;</span><span style="color:#C3E88D;">将以下英语文本翻译为法语：“</span><span style="color:#F78C6C;">{text}</span><span style="color:#C3E88D;">”</span><span style="color:#89DDFF;">&#39;</span><span style="color:#89DDFF;">}</span></span>
<span class="line"><span style="color:#89DDFF;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>甚至只是用户消息：</p><div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki material-theme-palenight"><code><span class="line"><span style="color:#A6ACCD;">[</span></span>
<span class="line"><span style="color:#A6ACCD;">{&quot;role&quot;：“user”，“content”：&#39;将以下英语文本翻译为法语：“{text}”}</span></span>
<span class="line"><span style="color:#A6ACCD;">]</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h2 id="常见问题" tabindex="-1">常见问题 <a class="header-anchor" href="#常见问题" aria-label="Permalink to &quot;常见问题&quot;">​</a></h2><h3 id="gpt-3-5-turbo-可以进行微调吗" tabindex="-1"><code>gpt-3.5-turbo</code> 可以进行微调吗？ <a class="header-anchor" href="#gpt-3-5-turbo-可以进行微调吗" aria-label="Permalink to &quot;\`gpt-3.5-turbo\` 可以进行微调吗？&quot;">​</a></h3><p>不。截至 2023 年 3 月 1 日，您只能对基本 <code>GPT-3</code> 模型进行微调。有关如何使用微调模型的更多详细信息，请参见<a href="https://platform.openai.com/docs/guides/fine-tuning" target="_blank" rel="noreferrer">微调指南</a>。</p><h3 id="你们是否存储通过-api-传递的数据" tabindex="-1">你们是否存储通过 API 传递的数据？ <a class="header-anchor" href="#你们是否存储通过-api-传递的数据" aria-label="Permalink to &quot;你们是否存储通过 API 传递的数据？&quot;">​</a></h3><p>截至 2023 年 3 月 1 日，我们保留 API 数据 30 天，但不再使用通过 API 发送的数据来改进我们的模型。请在我们的<a href="https://openai.com/policies/usage-policies" target="_blank" rel="noreferrer">数据使用政策</a>中了解更多。</p><h3 id="添加一个内容过滤层" tabindex="-1">添加一个内容过滤层 <a class="header-anchor" href="#添加一个内容过滤层" aria-label="Permalink to &quot;添加一个内容过滤层&quot;">​</a></h3><p>如果您想将内容审查层添加到 Chat API 的输出中，您可以按照我们的<a href="./../models.html#审核">内容审查指南</a>来防止显示违反 OpenAI 使用政策的内容。</p>`,59),e=[p];function t(r,c,D,F,y,i){return a(),n("div",null,e)}const A=s(o,[["render",t]]);export{u as __pageData,A as default};
