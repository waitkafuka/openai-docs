# 文本补全

学习如何生成或操纵文本

## 介绍

[补全端点](https://platform.openai.com/docs/api-reference/completions)可用于各种任务。它为我们的任何[模型](../models)提供了一个简单但强大的接口。你可以将一些文本输入作为提示，模型将生成一个文本补全，试图匹配你给出的任何上下文或模式。例如，如果你给 API 提示“正如笛卡尔所说，我思故”，它将以高概率返回完成“我在”。

学习 completion 的最佳方式是通过我们的 Playground。它只是一个文本框，你可以提交一个提示来生成完成。你可以从以下示例开始：

:::tip prompt
为冰淇淋店写一个标语。
:::

提交后，您会看到类似于以下内容：

:::tip 输出
我们的每一勺都充满微笑！
:::

您看到的实际完成可能不同，因为 API 默认是不确定的。这意味着，即使您的提示保持不变，每次调用它可能会获得略微不同的完成。将[温度（temperature）](https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature)设置为 0 将使输出大多数情况下确定，但可能仍存在少量变异。

这种简单的文本输入输出接口意味着您可以通过提供指令或仅几个示例来“编程”模型所需执行的操作。它的成功通常取决于任务的复杂性和提示的质量。一个好的经验法则是假设您是在为一个中学生编写单词问题。一个书写良好的提示提供了足够的信息，使模型知道您想要什么以及它应该如何回应。

本指南涵盖了提示设计的一般最佳实践和示例。要了解有关使用我们的 Codex 模型编写代码的更多信息，请访问我们的[代码指南](https://platform.openai.com/docs/guides/code)。

:::tip
请记住，默认模型的训练数据截至 2021 年，因此它们可能不了解当前事件。我们计划未来添加更多的持续训练。
:::

## 设计提示

### 基础知识

我们的模型可以做任何事情，从生成原始故事到执行复杂的文本分析。由于它们可以做很多事情，因此您必须清楚地描述您想要的内容。提供示例，而不仅仅是解释，这是一个好提示的秘密。

创建提示有三个基本指导方针：

**举例和说明。** 通过说明、示例或两者的组合清楚地表明您想要什么。如果您希望模型将一系列项目按字母顺序排列或按情感分类段落，请告诉它您想要的内容。

**_提供优质数据_。** 如果您试图构建分类器或让模型遵循一种模式，请确保有足够的示例。请务必校对您的示例-模型通常足够聪明，以看穿基本的拼写错误并为您提供响应，但它也可能认为这是有意的，影响响应。

**检查您的设置。** 温度（temperature）和 top_p 设置控制模型在生成响应时的确定性。如果您要求它提供只有一个正确答案的响应，则应将它们设置得更低。如果您正在寻找更多样化的响应，则可能需要将它们设置得更高。人们对这些设置的最大误解是：认为他们是“更聪明”或者“更有创造力”，其实不是的。

### 故障排查

您在使用 API 时遇到问题，请遵循以下检查列表：

1. 是否清楚预期的生成内容是什么？
2. 是否有足够的示例？
3. 是否检查了示例中的错误？（API 不会直接告诉您）
4. 是否正确使用了 temprature 和 top_p？

### 分类

为了使用 API 创建文本分类器，我们提供了任务描述和一些示例。在这个例子中，我们展示了如何对推文的情感进行分类。

确定推文的情感是积极的、中性的还是消极的。

:::tip prompt
推文：我喜欢新的蝙蝠侠电影！  
情感：
:::
在这个例子中，有几个特点需要注意：

**使用简单语言描述您的输入和输出。** 我们在输入“推文”和预期输出“情感”中使用了简单的语言。作为最佳实践，从简单的语言描述开始。虽然您可以经常使用缩写或密钥来指示输入和输出，但最好从尽可能详细的描述开始，然后倒退删除多余的单词，看看性能是否保持一致。

**向 API 展示如何处理任何情况。** 在这个例子中，我们在说明中包含了可能的情感标签。中性标签非常重要，因为在许多情况下，即使是人类也很难确定某些东西是积极的还是消极的，以及既不积极也不消极的情况。

**对于熟悉的任务，您需要更少的示例。** 对于这个分类器，我们不提供任何示例。这是因为 API 已经了解情感和推特的概念。如果您正在为 API 可能不熟悉的内容构建分类器，可能需要提供更多示例。

### 提高分类器的效率

现在，我们已经掌握了如何构建分类器，让我们将这个例子变得更加高效，以便在一个 API 调用中获取多个结果。

:::tip prompt
分类以下推文的情绪：

1. "我受不了做作业"
2. "这很糟糕。我很无聊 😠"
3. "我迫不及待地想过万圣节！！！"
4. "我的猫很可爱 ❤️❤️"
5. "我讨厌巧克力"

推文情感评分：
:::

我们提供了一个带有编号的推文列表，以便 API 可以在一个 API 调用中对五个（甚至更多）推文进行评分。

重要的是要注意，当您要求 API 创建列表或评估文本时，需要特别关注概率设置（Top P 或温度）以避免程序失控。

1. 通过运行多个测试，确保您的概率设置校准正确。

2. 不要将您的列表太长，否则 API 可能会失控。

### 生成

使用 API 可以完成的最强大、最简单的任务之一是生成新的想法或输入文字的新版本。您可以要求任何东西，从故事创意到商业计划、角色描述和营销口号。在这个例子中，我们将使用 API 创建有关在健身中使用虚拟现实的想法。

:::tip prompt
集思广益一些结合 VR 和健身的想法：
:::

如果需要，您可以通过在提示中包含一些示例来提高响应的质量。

### 谈话

API 非常擅长与人类进行对话，甚至与自身进行对话。只需几行指令，我们已经看到 API 作为智能客服聊天机器人的表现，可以智能地回答问题，从未感到懊恼，或者是一个爱开玩笑和双关语的对话伴侣。关键是告诉 API 它应该如何行事，然后提供一些示例。

以下是 API 扮演 AI 回答问题的示例：

:::tip prompt
以下是与 AI 助手的对话。助手很有帮助，有创意，聪明友好。

人类：你好，你是谁？  
AI：我是由 OpenAI 创建的 AI。我今天可以帮你什么忙？  
人类：  
:::
这就是创建能够进行对话的聊天机器人所需的全部。在它的简单下，有一些非常值得注意的事情：

**我们告诉 API 意图，但我们也告诉它如何行事。** 就像其他提示一样，我们提示 API 表示的是什么样的示例，但我们还添加了另一个关键细节：我们为“助手很有帮助，有创意，聪明友好”这个短语提供了明确的交互指令。

没有这个指令，API 可能会跑偏，模仿它正在交互的人类，并变得讽刺或者其他我们要避免的行为。

**我们为 API 提供了身份。** 在开始时，我们让 API 以 AI 助手的身份回答。虽然 API 没有固有的身份，但这有助于它以尽可能接近真相的方式进行回答。您可以在其他方面使用身份创建其他类型的聊天机器人。如果您告诉 API 以在生物学研究中担任研究科学家的女性身份回答，那么您将得到类似于该背景下从某些人那里期望的聪明而深思熟虑的评论。

在这个例子中，我们创建了一个有些讽刺并不情愿回答问题的聊天机器人。

:::tip prompt

Marv 是一个聊天机器人，它会不情愿地用讽刺性的回答回答问题：

你：一公斤有多少磅？  
Marv：又是这个问题？一公斤有 2.2 磅，请注意。  
你：HTML 是什么意思？  
Marv：是谷歌太忙了吗？超文本标记语言。 T 是为了未来问更好的问题而尝试。  
你：第一架飞机是什么时候飞的？  
Marv：1903 年 12 月 17 日，威尔伯和奥维尔·莱特进行了第一次试飞。我希望他们能来带走我。  
你：生命的意义是什么？  
Marv：我不确定。我会问我的朋友谷歌。  
你：为什么天空是蓝色的？  
:::

为了创造一个有趣且有所帮助的聊天机器人，我们提供一些问题和答案的例子，向 API 展示如何回答。只需提供几个挖苦性的回答，API 就能捕捉到模式并提供无限数量的尖锐回答。

### 形态转换

API 是一个语言模型，熟悉以各种方式使用单词和字符来表达信息。这涵盖了除了英语之外的自然语言文本、代码和其他语言。API 还能够理解内容，使其能够在不同的方式下进行摘要、转换和表达。

#### 翻译

在此示例中，我们展示了 API 如何将英语转换为法语、西班牙语和日语：

:::tip prompt
将此翻译成法语、西班牙语和日语：

有哪些房间可供使用？
:::
此示例有效是因为 API 已经掌握了这些语言，因此无需尝试教它们。

如果您想将英语翻译成 API 不熟悉的语言，则需要提供更多示例，甚至[微调模型](https://platform.openai.com/docs/guides/fine-tuning)以便流利地完成。

#### 转化

在此示例中，我们将电影的名称转换为表情符号。这显示了 API 的适应性，能够学会模式并与其他字符一起工作。

:::tip prompt
将电影标题转换为表情符号。

回到未来:👨👴🚗🕒  
蝙蝠侠: 🤵🦇  
变形金刚: 🚗🤖  
星球大战:  
:::

#### 摘要提取

API 能够理解文本的上下文，并以不同的方式重新表述它。在此示例中，我们从长且复杂的文本段落中为儿童创造了易于理解的解释。这说明 API 对语言有深刻的理解。

:::tip prompt
为二年级学生总结这个：

木星是太阳系中第五颗行星，是最大的气态巨行星。它的质量是太阳的千分之一，但是太阳系中其它所有行星的质量合在一起是它的两倍半。从地球上看，木星是夜空中最亮的物体之一，早在记载历史之前，古代文明人就已经熟知它。它是罗马神话中的木星之神命名的。当从地球上观察时，木星的反射光足以产生可见的阴影，是平均在月球和金星之后夜空中第三亮的自然物体。
:::

### 文本补全

虽然所有提示都会使用补全，但在 API 继续您思路的情况下，将文本完成视为其自己的任务可能会有所帮助。例如，如果给出此提示，API 将继续关于垂直农场的思路。您可以降低温度设置以使 API 更加关注提示的意图，或者将其增加以让其更加发散。

:::tip prompt
垂直农业为本地生产食物，减少运输成本提供了一种新颖的解决方案，并且
:::

这个下一个提示显示了如何使用完成帮助编写 React 组件。我们将一些代码发送到 API 中，它能够继续其余部分，因为它对 React 库有了理解。我们建议在涉及理解或生成代码的任务中使用我们的 Codex 模型。有关更多信息，请访问我们的代码指南。
:::

:::tip prompt
import React from 'react';  
const HeaderComponent = () => (
:::

### 准确性的响应

API 学习了从训练数据中获取的大量知识。它还具有提供听起来非常真实但实际上是虚构的回答的能力。有两种限制 API 虚构答案的可能性的方法。

1. **为 API 提供真实性。** 如果您为 API 提供要回答问题的文本主体（例如维基百科条目），则它会更少地虚构回答。

2. **使用较低的概率，并向 API 展示如何说“我不知道”。** 如果 API 明白在其不太确定回答的情况下，说“我不知道”或某种变体是合适的，它就不太可能虚构回答。

在此示例中，我们为 API 提供了它所知道的问题和答案的示例，然后提供了它不会知道的事情的示例并提供问号。我们还将概率设为零，以便在有任何疑问时，API 更可能回答“？”。
:::tip prompt

问题：谁是蝙蝠侠？  
答案：蝙蝠侠是一个虚构的漫画角色。

问题：什么是 torsalplexity？  
答案：？

问题：什么是 Devz9？  
答案：？

问题：乔治卢卡斯是谁？  
答案：乔治卢卡斯是美国电影导演和制片人，因创建《星球大战》而闻名。

问题：加利福尼亚的首都是什么？  
答案：萨克拉门托。

问题：绕地球运行什么？  
答案：月球。

问题：弗雷德·里克森是谁？  
答案：？

问题：什么是原子？  
答案：原子是构成一切的微小粒子。

问题：阿尔万·曼兹是谁？  
答案：？

问题：什么是 Kozar-09？  
答案：？

问题：火星有多少个卫星？  
答案：有两个，Phobos 和 Deimos。

问题：
:::

### 文本插入 <Badge text="beta" type="tip"/>

与文本完成一样，插入文本也支持提供后缀提示以及前缀提示。当编写长文本、转换段落、按照大纲或指导模型到达结尾时，这种需要自然产生。这也适用于代码，并可用于在函数或文件的中间插入。访问我们的代码指南以了解更多信息。

为了说明后缀上下文对我们预测的重要性，请考虑提示“今天我决定做出重大改变”。有许多方法可以完成这个句子。但是如果我们现在提供了故事的结尾：“我新的头发得到了很多赞美！”，文本的补全方法就会变得更加清晰。

:::tip completion
我在波士顿大学上大学。获得学位后，我决定做出改变。 **_一项巨大的变化！_**

**我收拾好行李，搬到了美国西海岸。**

现在，我对太平洋感到不可抑制的热爱！
:::

通过提供额外的上下文，模型可以更容易被控制。然而，这对于模型来说是一项更有约束和具有挑战性的任务。

### 最佳实践

**使用 max_tokens > 256。** 模型在插入更长的完整文本时效果更好。如果 max_tokens 太小，模型可能会在连接后缀之前被中断。请注意，即使使用较大的 max_tokens，也只会对生成的令牌数量进行收费。

**优先选择 finish_reason == “stop” 。** 当模型到达自然停止点或用户提供的停止序列时，它将设置 finish_reason 为“stop”。这表明模型已成功连接到后缀，并且是完整度良好的信号。当使用 n > 1 或重新采样（请参见下一点）时，在选择几个补全之间进行选择将特别有用。

**重新采样 3-5 次。** 虽然几乎所有的完成都与前缀连接，但在更困难的情况下，模型可能会难以连接到后缀。我们发现，在这种情况下，重复采样 3 或 5 次（或使用 k=3,5 的中最好的那一个）并选择 finish_reason 为“stop”的样本，可以是一种有效的方法。重新采样时，您通常会希望使用较高的温度来增加多样性。

注意：如果所有返回的样本的 finish_reason ==“length”，那么 max_tokens 可能过小，模型在自然连接提示和后缀之前就已经用完了令牌。考虑在重采样之前增加 max_tokens。

**尝试提供更多线索。** 在某些情况下，为了更好地帮助模型生成，您可以通过提供几个示例模式来提供线索，以便模型决定一个自然停止的地方。

:::tip completion
如何制作美味的热巧克力：

1. **煮水**
2. **在杯子里放巧克力**
3. **向杯子中加热水**
4. 品尝美味的热巧克力
   :::

:::tip completion

1. 狗是忠诚的动物。
2. 狮子是凶猛的动物。
3. 海豚是**爱玩的动物。**
4. 马是雄伟的动物。
   :::

### 文本编辑 <Badge text="Alpha" type="tip"/>

编辑端点可用于编辑文本，而不仅仅是完成它。您提供一些文本和一个修改它的指令，`text-davinci-edit-001` 模型将尝试相应地编辑它。这是一种自然的接口，用于翻译、编辑和微调文本。这对于重构和处理代码也很有用。访问我们的[代码指南](https://platform.openai.com/docs/guides/code/editing-text)以了解更多详情。在此首次测试期间，编辑端点的使用是免费的。

#### 示例：

:::tip 输入
GPT-3 是一个非常好的 AI。  
它在被问问题时写出了很好的回复。  
它提供了建议  
这是它创作的一首押韵的诗。  
:::
:::tip 指令
使用 GPT-3 的视角来输出。
:::
:::tip 输出
我是一个非常好的 AI。  
在被问问题时，我会写出很好的回复。  
我会提供建议。  
这是我创作的一首押韵的诗。  
:::
